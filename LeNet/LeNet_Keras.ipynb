{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have completed the implementation in PyTorch, lets also implement it in Keras.\n",
        "It should be easier(by that I mean shorter) than the PyTorch implementation."
      ],
      "metadata": {
        "id": "Mml73JLPoJGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datset preparation:"
      ],
      "metadata": {
        "id": "Q91Iw5G5UteU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpRr2TLLUgHW"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fvebPJHUlF4",
        "outputId": "978fafe1-642d-4dc4-b062-a4f044b22a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9nN7zbE9VuGg",
        "outputId": "6d43e9d3-916b-4817-e27c-bde5d87f954b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a36346bee90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHlgYttUsbD",
        "outputId": "a6708298-93b0-4246-c1f9-ebb43c4f4cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing:"
      ],
      "metadata": {
        "id": "8zRb_E5WXToF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is no information on channels, we need to manually specify that the image has 1 channel. So lets do that for x_train and x_test."
      ],
      "metadata": {
        "id": "wVuFkzieVJP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "DB8T_oovUxZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSxtdLPnVAtl",
        "outputId": "2b4c3f77-8609-417b-ba68-018c093e2407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets normalize the pixel values as well"
      ],
      "metadata": {
        "id": "LQcIifeLWd9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "InaNwVQfWhOG",
        "outputId": "a751784a-3432-4988-d0fb-1af12342946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  3]\n",
            "  [ 18]\n",
            "  [ 18]\n",
            "  [ 18]\n",
            "  [126]\n",
            "  [136]\n",
            "  [175]\n",
            "  [ 26]\n",
            "  [166]\n",
            "  [255]\n",
            "  [247]\n",
            "  [127]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 30]\n",
            "  [ 36]\n",
            "  [ 94]\n",
            "  [154]\n",
            "  [170]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [225]\n",
            "  [172]\n",
            "  [253]\n",
            "  [242]\n",
            "  [195]\n",
            "  [ 64]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 49]\n",
            "  [238]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [251]\n",
            "  [ 93]\n",
            "  [ 82]\n",
            "  [ 82]\n",
            "  [ 56]\n",
            "  [ 39]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [219]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [198]\n",
            "  [182]\n",
            "  [247]\n",
            "  [241]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 80]\n",
            "  [156]\n",
            "  [107]\n",
            "  [253]\n",
            "  [253]\n",
            "  [205]\n",
            "  [ 11]\n",
            "  [  0]\n",
            "  [ 43]\n",
            "  [154]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 14]\n",
            "  [  1]\n",
            "  [154]\n",
            "  [253]\n",
            "  [ 90]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [139]\n",
            "  [253]\n",
            "  [190]\n",
            "  [  2]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 11]\n",
            "  [190]\n",
            "  [253]\n",
            "  [ 70]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 35]\n",
            "  [241]\n",
            "  [225]\n",
            "  [160]\n",
            "  [108]\n",
            "  [  1]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 81]\n",
            "  [240]\n",
            "  [253]\n",
            "  [253]\n",
            "  [119]\n",
            "  [ 25]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 45]\n",
            "  [186]\n",
            "  [253]\n",
            "  [253]\n",
            "  [150]\n",
            "  [ 27]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 16]\n",
            "  [ 93]\n",
            "  [252]\n",
            "  [253]\n",
            "  [187]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [249]\n",
            "  [253]\n",
            "  [249]\n",
            "  [ 64]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 46]\n",
            "  [130]\n",
            "  [183]\n",
            "  [253]\n",
            "  [253]\n",
            "  [207]\n",
            "  [  2]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 39]\n",
            "  [148]\n",
            "  [229]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [250]\n",
            "  [182]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 24]\n",
            "  [114]\n",
            "  [221]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [201]\n",
            "  [ 78]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 23]\n",
            "  [ 66]\n",
            "  [213]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [198]\n",
            "  [ 81]\n",
            "  [  2]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [171]\n",
            "  [219]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [195]\n",
            "  [ 80]\n",
            "  [  9]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 55]\n",
            "  [172]\n",
            "  [226]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [244]\n",
            "  [133]\n",
            "  [ 11]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [136]\n",
            "  [253]\n",
            "  [253]\n",
            "  [253]\n",
            "  [212]\n",
            "  [135]\n",
            "  [132]\n",
            "  [ 16]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization**:"
      ],
      "metadata": {
        "id": "S5wuDgMxXaLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "OfDdyycVVcjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vuztoP-MWPAH",
        "outputId": "85e3e4a3-d298-4123-c00e-187a1e82a405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.01176471]\n",
            "  [0.07058824]\n",
            "  [0.07058824]\n",
            "  [0.07058824]\n",
            "  [0.49411765]\n",
            "  [0.53333333]\n",
            "  [0.68627451]\n",
            "  [0.10196078]\n",
            "  [0.65098039]\n",
            "  [1.        ]\n",
            "  [0.96862745]\n",
            "  [0.49803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.11764706]\n",
            "  [0.14117647]\n",
            "  [0.36862745]\n",
            "  [0.60392157]\n",
            "  [0.66666667]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.88235294]\n",
            "  [0.6745098 ]\n",
            "  [0.99215686]\n",
            "  [0.94901961]\n",
            "  [0.76470588]\n",
            "  [0.25098039]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.19215686]\n",
            "  [0.93333333]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.98431373]\n",
            "  [0.36470588]\n",
            "  [0.32156863]\n",
            "  [0.32156863]\n",
            "  [0.21960784]\n",
            "  [0.15294118]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.07058824]\n",
            "  [0.85882353]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.77647059]\n",
            "  [0.71372549]\n",
            "  [0.96862745]\n",
            "  [0.94509804]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.31372549]\n",
            "  [0.61176471]\n",
            "  [0.41960784]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.80392157]\n",
            "  [0.04313725]\n",
            "  [0.        ]\n",
            "  [0.16862745]\n",
            "  [0.60392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.05490196]\n",
            "  [0.00392157]\n",
            "  [0.60392157]\n",
            "  [0.99215686]\n",
            "  [0.35294118]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.54509804]\n",
            "  [0.99215686]\n",
            "  [0.74509804]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.04313725]\n",
            "  [0.74509804]\n",
            "  [0.99215686]\n",
            "  [0.2745098 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.1372549 ]\n",
            "  [0.94509804]\n",
            "  [0.88235294]\n",
            "  [0.62745098]\n",
            "  [0.42352941]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.31764706]\n",
            "  [0.94117647]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.46666667]\n",
            "  [0.09803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.17647059]\n",
            "  [0.72941176]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.58823529]\n",
            "  [0.10588235]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.0627451 ]\n",
            "  [0.36470588]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.73333333]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.97647059]\n",
            "  [0.99215686]\n",
            "  [0.97647059]\n",
            "  [0.25098039]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.18039216]\n",
            "  [0.50980392]\n",
            "  [0.71764706]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.81176471]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.15294118]\n",
            "  [0.58039216]\n",
            "  [0.89803922]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.98039216]\n",
            "  [0.71372549]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09411765]\n",
            "  [0.44705882]\n",
            "  [0.86666667]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.78823529]\n",
            "  [0.30588235]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09019608]\n",
            "  [0.25882353]\n",
            "  [0.83529412]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.77647059]\n",
            "  [0.31764706]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.07058824]\n",
            "  [0.67058824]\n",
            "  [0.85882353]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.76470588]\n",
            "  [0.31372549]\n",
            "  [0.03529412]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.21568627]\n",
            "  [0.6745098 ]\n",
            "  [0.88627451]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.95686275]\n",
            "  [0.52156863]\n",
            "  [0.04313725]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.53333333]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.83137255]\n",
            "  [0.52941176]\n",
            "  [0.51764706]\n",
            "  [0.0627451 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqER3qrcWvOW",
        "outputId": "038fb6b0-b8e5-47d1-ace2-e1dec19201e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**:\n",
        "\n",
        "As we can see, the target labels are the actual values.\n",
        "The output of the final layer of our architecture is a vector of 10 values.\n",
        "\n",
        "So to make them comparable to calculate the loss, lets do `one-hot-encoding` for target labels"
      ],
      "metadata": {
        "id": "66XsQvABW1E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "ljzgf4U_XH3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lnur4Z9XKJ2",
        "outputId": "eb38a0a4-f89d-49e6-f7ad-1420884f11d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet Model Architecture:\n",
        "\n",
        "The documentation specifies the following parameters to be provided:\n",
        "\n",
        "tf.keras.layers.Conv2D( \\\\\n",
        "    filters,   \\\\\n",
        "    kernel_size, \\\\\n",
        "    strides=(1, 1), \\\\\n",
        "    padding='valid', \\\\\n",
        "    data_format=None, \\\\\n",
        "    dilation_rate=(1, 1), \\\\\n",
        "    groups=1, \\\\\n",
        "    activation=None, \\\\\n",
        "    use_bias=True, \\\\\n",
        "    kernel_initializer='glorot_uniform', \\\\\n",
        "    bias_initializer='zeros', \\\\\n",
        "    kernel_regularizer=None, \\\\\n",
        "    bias_regularizer=None, \\\\\n",
        "    activity_regularizer=None, \\\\\n",
        "    kernel_constraint=None, \\\\\n",
        "    bias_constraint=None, \\\\\n",
        "    **kwargs \\\\\n",
        ")`\n"
      ],
      "metadata": {
        "id": "xk_u3-j4XMcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WgwNPIv6pQBm",
        "outputId": "f6b8c17d-1179-495e-ef97-51e19096924d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "_WSSU4bBWBp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building:\n",
        "\n",
        "Lets make a model1 with relu activation function in cnn layers"
      ],
      "metadata": {
        "id": "ReRC1XINp8cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Conv2D(filters = 6, kernel_size=(5,5), strides = (1,1), padding = 'valid', activation ='relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model1.add(Conv2D(filters = 16, kernel_size=(5, 5), activation='relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "model1.add(Dense(120, activation='relu'))\n",
        "model1.add(Dense(84, activation='relu'))\n",
        "model1.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "UaeJWY0PZz5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compilation:\n",
        "\n",
        "Remember the mnemonic `LOM` from the ANN_Tensorflow.ipynb? LOM as in Loss, optimizer, metrics have to be specified during compilation.\n",
        "\n",
        "Other parameters can be seen in the documentation: https://keras.io/api/models/model_training_apis/\n"
      ],
      "metadata": {
        "id": "wuzIT0RUrtrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import categorical_crossentropy\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "z9JbD7S5qz_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(\n",
        "    loss = categorical_crossentropy,\n",
        "    optimizer = optimizers.Adam(),\n",
        "    metrics = ['Accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "tJ8v8Thuqh6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training / Fitting:\n",
        "\n",
        "We must specify features, labels, batch size, epochs as parameters. Additional parameters can be referred in the documentation as well.\n",
        "\n",
        "The parameter `validation_data` is the data on which to evaluate the loss and any model metrics at the end of each epoch."
      ],
      "metadata": {
        "id": "79QOn0eurwmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train, y_train, batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJxNdAX0rSJz",
        "outputId": "d61c5a17-e2f1-4f5f-db00-7296d8a43ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - Accuracy: 0.7875 - loss: 0.6789 - val_Accuracy: 0.9728 - val_loss: 0.0924\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - Accuracy: 0.9706 - loss: 0.0979 - val_Accuracy: 0.9823 - val_loss: 0.0591\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Accuracy: 0.9805 - loss: 0.0666 - val_Accuracy: 0.9847 - val_loss: 0.0509\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9841 - loss: 0.0502 - val_Accuracy: 0.9842 - val_loss: 0.0498\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9862 - loss: 0.0426 - val_Accuracy: 0.9890 - val_loss: 0.0370\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9896 - loss: 0.0325 - val_Accuracy: 0.9870 - val_loss: 0.0406\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9895 - loss: 0.0319 - val_Accuracy: 0.9889 - val_loss: 0.0362\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Accuracy: 0.9929 - loss: 0.0246 - val_Accuracy: 0.9881 - val_loss: 0.0383\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Accuracy: 0.9922 - loss: 0.0237 - val_Accuracy: 0.9892 - val_loss: 0.0344\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9938 - loss: 0.0205 - val_Accuracy: 0.9892 - val_loss: 0.0383\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9938 - loss: 0.0176 - val_Accuracy: 0.9895 - val_loss: 0.0343\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9949 - loss: 0.0146 - val_Accuracy: 0.9877 - val_loss: 0.0409\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9954 - loss: 0.0140 - val_Accuracy: 0.9890 - val_loss: 0.0362\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Accuracy: 0.9962 - loss: 0.0117 - val_Accuracy: 0.9878 - val_loss: 0.0439\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Accuracy: 0.9963 - loss: 0.0109 - val_Accuracy: 0.9889 - val_loss: 0.0425\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9967 - loss: 0.0098 - val_Accuracy: 0.9898 - val_loss: 0.0404\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9972 - loss: 0.0085 - val_Accuracy: 0.9880 - val_loss: 0.0421\n",
            "Epoch 18/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9970 - loss: 0.0087 - val_Accuracy: 0.9888 - val_loss: 0.0485\n",
            "Epoch 19/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9975 - loss: 0.0076 - val_Accuracy: 0.9892 - val_loss: 0.0474\n",
            "Epoch 20/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9969 - loss: 0.0094 - val_Accuracy: 0.9900 - val_loss: 0.0430\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a3614de50f0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Prediction / Evaluation:"
      ],
      "metadata": {
        "id": "CWZd0JLjtyeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**:\n",
        "\n",
        "Lets try to predict on a sample instance and see if its correct."
      ],
      "metadata": {
        "id": "f-Ix60GQxMeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "instance = np.expand_dims(x_test[0], axis = 0)\n",
        "output = model1.predict(instance)\n",
        "print(output)\n",
        "print(np.argmax(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuUZejlwvS_8",
        "outputId": "c5628196-e63a-460b-ade9-a39e621ade67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "[[7.0102704e-15 8.7244899e-11 5.9170431e-13 2.5801661e-10 6.8798034e-09\n",
            "  1.4410722e-14 1.4683159e-17 1.0000000e+00 2.5157016e-12 8.7757940e-11]]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[0])\n",
        "print(np.argmax(y_test[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5wbad7wc0A",
        "outputId": "d2c78ecf-2d25-4ea3-c032-a340c1f5ab2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus the prediction is correct."
      ],
      "metadata": {
        "id": "eOoDHeMQxTYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**:\n",
        "\n",
        "To evaluate the overall model on test dataset, we use `model.evaluate`, which requires the features (x_test) and labels (y_test) to be passed as parameters. Other additional parameters can be supplied such as batch_size, steps, etc.."
      ],
      "metadata": {
        "id": "WL4QXVGWwsZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sah1QMXs7Er",
        "outputId": "833b4e07-f03f-4830-a98b-0eed30a43431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Accuracy: 0.9876 - loss: 0.0561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKyo7MN2u4UF",
        "outputId": "d0ab43b1-948c-4314-c048-ed9d228b07a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57t-s2KauxDl",
        "outputId": "3df297c1-beaf-4ef5-95d6-c95a1ef75af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.04303562641143799\n",
            "Test accuracy: 0.9900000095367432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, the LeNet architecture achieves very high accuracy."
      ],
      "metadata": {
        "id": "KQAimj3Yxvqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified LeNet Architecture:\n",
        "\n",
        "Notice that we used `relu` activation in the above LeNet architecture. So what if we use `tanh` instead? Lets quickly modify the architecture by using tanh activation function and go through the same steps and compare the accuracy."
      ],
      "metadata": {
        "id": "awb2OfifxYck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(filters = 6, kernel_size=(5,5), strides = (1,1), padding = 'valid', activation ='tanh'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(filters = 16, kernel_size=(5, 5), activation='tanh'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(120, activation='relu'))\n",
        "model2.add(Dense(84, activation='relu'))\n",
        "model2.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "hz1zWa8bxu3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(\n",
        "    loss = categorical_crossentropy,\n",
        "    optimizer = optimizers.Adam(),\n",
        "    metrics = ['Accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ver0LAC4x-0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_train, y_train, batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWZoDvwZyTuR",
        "outputId": "982b708b-c5ba-468b-8975-a30cb1372489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - Accuracy: 0.8108 - loss: 0.6685 - val_Accuracy: 0.9708 - val_loss: 0.0964\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9706 - loss: 0.0977 - val_Accuracy: 0.9784 - val_loss: 0.0633\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9801 - loss: 0.0628 - val_Accuracy: 0.9842 - val_loss: 0.0466\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9852 - loss: 0.0469 - val_Accuracy: 0.9831 - val_loss: 0.0553\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9879 - loss: 0.0368 - val_Accuracy: 0.9842 - val_loss: 0.0494\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9903 - loss: 0.0303 - val_Accuracy: 0.9867 - val_loss: 0.0450\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Accuracy: 0.9917 - loss: 0.0251 - val_Accuracy: 0.9867 - val_loss: 0.0410\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Accuracy: 0.9931 - loss: 0.0215 - val_Accuracy: 0.9877 - val_loss: 0.0387\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9941 - loss: 0.0193 - val_Accuracy: 0.9868 - val_loss: 0.0435\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Accuracy: 0.9954 - loss: 0.0145 - val_Accuracy: 0.9869 - val_loss: 0.0456\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9955 - loss: 0.0135 - val_Accuracy: 0.9866 - val_loss: 0.0522\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - Accuracy: 0.9966 - loss: 0.0112 - val_Accuracy: 0.9857 - val_loss: 0.0516\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Accuracy: 0.9957 - loss: 0.0130 - val_Accuracy: 0.9871 - val_loss: 0.0480\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9977 - loss: 0.0076 - val_Accuracy: 0.9871 - val_loss: 0.0546\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9963 - loss: 0.0103 - val_Accuracy: 0.9882 - val_loss: 0.0517\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9975 - loss: 0.0077 - val_Accuracy: 0.9874 - val_loss: 0.0559\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9977 - loss: 0.0069 - val_Accuracy: 0.9885 - val_loss: 0.0508\n",
            "Epoch 18/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Accuracy: 0.9978 - loss: 0.0068 - val_Accuracy: 0.9860 - val_loss: 0.0532\n",
            "Epoch 19/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9983 - loss: 0.0056 - val_Accuracy: 0.9892 - val_loss: 0.0493\n",
            "Epoch 20/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Accuracy: 0.9978 - loss: 0.0063 - val_Accuracy: 0.9872 - val_loss: 0.0580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a35969e3850>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score2 = model2.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RtP9QHXyYd4",
        "outputId": "cb725574-1b5f-41c8-cee5-5604a1c7ed2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Accuracy: 0.9827 - loss: 0.0771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test loss:\", score2[0])\n",
        "print(\"Test accuracy:\", score2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-BegPyyyrQq",
        "outputId": "872771b2-9e6c-40d2-fbe3-8e33bcbf4dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.058044642210006714\n",
            "Test accuracy: 0.9872000217437744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy doesn't vary as much. You may try to experiment some more with the architecture as well."
      ],
      "metadata": {
        "id": "6UDUQ5f7zEAb"
      }
    }
  ]
}